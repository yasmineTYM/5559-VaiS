# 5559-VaiS
# AI meet VIS  - OSE 5559 course 

This is build for group work, may include all the information and materials used in our course, including but not limited to:

- paper list(NLP focused)
- paper summary
- presentation slides
- final work 

# Paper List

##### Classification problem
-  Understanding Convolutional Neural Networks for Text Classification

##### Sentiment analysis
- [Importance of Self-Attention for Sentiment Analysis](https://www.aclweb.org/anthology/W18-5429.pdf)
- [Adversarial Attack on Sentiment Classification](https://www.aclweb.org/anthology/W19-4824.pdf)
- [Sentiment analysis is not solved! Assessing and probing sentiment classification](https://arxiv.org/pdf/1906.05887.pdf)
##### Self-Attention 
- [Detecting Political Bias in News Articles Using Headline Attention](https://www.aclweb.org/anthology/W19-4809.pdf)
- [What does BERT look at? An Analysis of BERT’s Attention](https://arxiv.org/pdf/1906.04341.pdf)
- [Analyzing the Structure of Attention in a Transformer Language Model](https://arxiv.org/pdf/1906.04284.pdf)

##### Interpreting model
* Interpreting Neural Networks with Nearest Neighbors
* Interpretable Neural Architectures for Attributing an Ad’s Performance to its Writing Style
* Learning Explanations from Language Data
* Open Sesame: Getting Inside BERT’s Linguistic Knowledge

##### Knowledge Graph
- Modeling Paths for Explainable Knowledge Base Completion

##### Graph Neural Network
- [GNNExplainer: Generating Explanations for Graph Neural Networks](https://cs.stanford.edu/people/jure/pubs/gnnexplainer-neurips19.pdf)
- [Interpretable Graph Convolutional Neural Networks for Inference on Noisy Knowledge Graphs](https://arxiv.org/pdf/1812.00279.pdf)

##### Others 
 - [Analyzing Learned Representations of a Deep ASR Performance Prediction Model](https://arxiv.org/pdf/1808.08573.pdf)
 - Evaluating Textual Representations through Image Generation
 - LISA: Explaining Recurrent Neural Network Judgments via Layer-wIse Semantic Accumulation and Example to Pattern Transformation
 - Interpretable Textual Neuron Representations for NLP
 - Interpretable Word Embedding Contextualization
 - Portable, layer-wise task performance monitoring for NLP models
 - Debugging Sequence-to-Sequence Models with SEQ2SEQ-VIS
 - Multi-Granular Text Encoding for Self-Explaining Categorization
 - Evaluating Recurrent Neural Network Explanations
